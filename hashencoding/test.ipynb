{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCNN WARNING: input must be a CUDA tensor, but isn't. This indicates suboptimal performance.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "M:\\tinycnn\\tiny-cuda-nn\\bindings\\torch\\tinycudann\\bindings.cpp:82 check failed input.size(1) == n_input_dims()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\TiNeuVox\\hashencoding\\test.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TiNeuVox/hashencoding/test.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m x_samples \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, resolution)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TiNeuVox/hashencoding/test.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m grid \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(torch\u001b[39m.\u001b[39mmeshgrid([x_samples, x_samples, x_samples], indexing\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mij\u001b[39m\u001b[39m\"\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/TiNeuVox/hashencoding/test.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m encoded_values \u001b[39m=\u001b[39m encoder(grid)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TiNeuVox/hashencoding/test.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mmax(encoded_values))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TiNeuVox/hashencoding/test.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mmin(encoded_values))\n",
      "File \u001b[1;32mc:\\Users\\Sora\\anaconda3\\envs\\TestOldPython\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\TiNeuVox\\hashencoding\\field_components\\encodings.py:255\u001b[0m, in \u001b[0;36mHashEncoding.forward\u001b[1;34m(self, in_tensor)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, in_tensor: Float[Tensor, \u001b[39m\"\u001b[39m\u001b[39m*bs input_dim\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Float[Tensor, \u001b[39m\"\u001b[39m\u001b[39m*bs output_dim\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtcnn_encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtcnn_encoding(in_tensor)\n\u001b[0;32m    256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpytorch_fwd(in_tensor)\n",
      "File \u001b[1;32mc:\\Users\\Sora\\anaconda3\\envs\\TestOldPython\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Sora\\anaconda3\\envs\\TestOldPython\\lib\\site-packages\\tinycudann-1.6-py3.9-win-amd64.egg\\tinycudann\\modules.py:119\u001b[0m, in \u001b[0;36mModule.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    116\u001b[0m padded_batch_size \u001b[39m=\u001b[39m (batch_size \u001b[39m+\u001b[39m batch_size_granularity\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size_granularity \u001b[39m*\u001b[39m batch_size_granularity\n\u001b[0;32m    118\u001b[0m x_padded \u001b[39m=\u001b[39m x \u001b[39mif\u001b[39;00m batch_size \u001b[39m==\u001b[39m padded_batch_size \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mpad(x, [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, padded_batch_size \u001b[39m-\u001b[39m batch_size])\n\u001b[1;32m--> 119\u001b[0m output \u001b[39m=\u001b[39m _module_function\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    120\u001b[0m \t\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnative_tcnn_module,\n\u001b[0;32m    121\u001b[0m \tx_padded\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mfloat)\u001b[39m.\u001b[39;49mcontiguous(),\n\u001b[0;32m    122\u001b[0m \t\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mto(_torch_precision(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnative_tcnn_module\u001b[39m.\u001b[39;49mparam_precision()))\u001b[39m.\u001b[39;49mcontiguous(),\n\u001b[0;32m    123\u001b[0m \t\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_scale\n\u001b[0;32m    124\u001b[0m )\n\u001b[0;32m    125\u001b[0m \u001b[39mreturn\u001b[39;00m output[:batch_size, :\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_output_dims]\n",
      "File \u001b[1;32mc:\\Users\\Sora\\anaconda3\\envs\\TestOldPython\\lib\\site-packages\\torch\\autograd\\function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mapply(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[0;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sora\\anaconda3\\envs\\TestOldPython\\lib\\site-packages\\tinycudann-1.6-py3.9-win-amd64.egg\\tinycudann\\modules.py:31\u001b[0m, in \u001b[0;36m_module_function.forward\u001b[1;34m(ctx, native_tcnn_module, input, params, loss_scale)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(ctx, native_tcnn_module, \u001b[39minput\u001b[39m, params, loss_scale):\n\u001b[0;32m     27\u001b[0m \t\u001b[39m# If no output gradient is provided, no need to\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \t\u001b[39m# automatically materialize it as torch.zeros.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \tctx\u001b[39m.\u001b[39mset_materialize_grads(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 31\u001b[0m \tnative_ctx, output \u001b[39m=\u001b[39m native_tcnn_module\u001b[39m.\u001b[39;49mfwd(\u001b[39minput\u001b[39;49m, params)\n\u001b[0;32m     32\u001b[0m \tctx\u001b[39m.\u001b[39msave_for_backward(\u001b[39minput\u001b[39m, params, output)\n\u001b[0;32m     33\u001b[0m \tctx\u001b[39m.\u001b[39mnative_tcnn_module \u001b[39m=\u001b[39m native_tcnn_module\n",
      "\u001b[1;31mRuntimeError\u001b[0m: M:\\tinycnn\\tiny-cuda-nn\\bindings\\torch\\tinycudann\\bindings.cpp:82 check failed input.size(1) == n_input_dims()"
     ]
    }
   ],
   "source": [
    "# COLLAPSED\n",
    "import torch\n",
    "import mediapy as media\n",
    "from field_components import encodings as encoding\n",
    "\n",
    "num_levels = 8\n",
    "min_res = 2\n",
    "max_res = 128\n",
    "log2_hashmap_size = 4  # Typically much larger tables are used\n",
    "\n",
    "resolution = 128\n",
    "slice = 0\n",
    "\n",
    "# Fixing features_per_level to 3 for easy RGB visualization. Typical value is 2 in networks\n",
    "features_per_level = 4\n",
    "\n",
    "encoder = encoding.HashEncoding(\n",
    "    num_levels=num_levels,\n",
    "    min_res=min_res,\n",
    "    max_res=max_res,\n",
    "    log2_hashmap_size=log2_hashmap_size,\n",
    "    features_per_level=features_per_level,\n",
    "    hash_init_scale=0.001,\n",
    "    implementation=\"tcnn\",\n",
    ")\n",
    "\n",
    "x_samples = torch.linspace(0, 1, resolution)\n",
    "grid = torch.stack(torch.meshgrid([x_samples, x_samples, x_samples], indexing=\"ij\"), dim=-1)\n",
    "\n",
    "encoded_values = encoder(grid)\n",
    "print(torch.max(encoded_values))\n",
    "print(torch.min(encoded_values))\n",
    "\n",
    "grid_slice = grid[slice, ...]\n",
    "encoded_values_slice = encoded_values[slice, ...]\n",
    "\n",
    "print(\"Input Values:\")\n",
    "media.show_images(torch.moveaxis(grid_slice, 2, 0), cmap=\"plasma\", border=True)\n",
    "\n",
    "print(\"Encoded Values:\")\n",
    "encoded_images = encoded_values_slice.view(resolution, resolution, num_levels, 3)\n",
    "encoded_images = torch.moveaxis(encoded_images, 2, 0)\n",
    "encoded_images -= torch.min(encoded_images)\n",
    "encoded_images /= torch.max(encoded_images)\n",
    "media.show_images(encoded_images.detach().numpy(), cmap=\"plasma\", border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rf_compression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
